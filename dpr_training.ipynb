{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0749c9d-94f1-4d5d-881b-c743bb6102ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:38:31.995460Z",
     "start_time": "2025-09-05T16:38:28.796036Z"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu128\n",
      "0.23.0+cu128\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)       # should be 2.8.0\n",
    "print(torchvision.__version__)  # should be 0.15.2\n",
    "print(torch.cuda.is_available())  # should be True if GPU available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3fbf5e-6a08-41b2-8c14-c84e3f9c04ac",
   "metadata": {},
   "source": [
    "From the dataset on the website, sample some data from triples.train for training & testing since dataset is large enough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291fc158-72de-4e99-a49a-1aa50165694d",
   "metadata": {},
   "source": [
    "This code samples some data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07538c9-e0b8-4c14-ae15-2f0c3bbf91e2",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"/teamspace/studios/this_studio/triples_chunk1000.tsv\"\n",
    "OUTPUT_PATH = \"/teamspace/studios/this_studio/triples_sample_10k.tsv\"\n",
    "\n",
    "# Load the full TSV\n",
    "df = pd.read_csv(DATA_PATH, sep=\"\\t\", names=[\"query\", \"positive\", \"negative\"])\n",
    "\n",
    "# Sample 10,000 rows randomly (or fewer if the file has less)\n",
    "sample_df = df.sample(n=min(100, len(df)), random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save to a new TSV\n",
    "sample_df.to_csv(OUTPUT_PATH, sep=\"\\t\", index=False)\n",
    "\n",
    "print(f\"Sampled {len(sample_df)} rows and saved to {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619730a-5d6c-4a8a-882c-0026079d3d2b",
   "metadata": {},
   "source": [
    "Viewing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2405322b-b961-4368-9773-e4bcf517f0f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-05T16:38:37.036087Z",
     "start_time": "2025-09-05T16:38:34.378763Z"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files downloaded and extracted.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is a little caffeine ok during pregnancy</td>\n",
       "      <td>We donât know a lot about the effects of caf...</td>\n",
       "      <td>It is generally safe for pregnant women to eat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what fruit is native to australia</td>\n",
       "      <td>Passiflora herbertiana. A rare passion fruit n...</td>\n",
       "      <td>The kola nut is the fruit of the kola tree, a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how large is the canadian military</td>\n",
       "      <td>The Canadian Armed Forces. 1  The first large-...</td>\n",
       "      <td>The Canadian Physician Health Institute (CPHI)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>types of fruit trees</td>\n",
       "      <td>Cherry. Cherry trees are found throughout the ...</td>\n",
       "      <td>The kola nut is the fruit of the kola tree, a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how many calories a day are lost breastfeeding</td>\n",
       "      <td>Not only is breastfeeding better for the baby,...</td>\n",
       "      <td>However, you still need some niacin each day; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            query  \\\n",
       "0        is a little caffeine ok during pregnancy   \n",
       "1               what fruit is native to australia   \n",
       "2              how large is the canadian military   \n",
       "3                            types of fruit trees   \n",
       "4  how many calories a day are lost breastfeeding   \n",
       "\n",
       "                                            positive  \\\n",
       "0  We donât know a lot about the effects of caf...   \n",
       "1  Passiflora herbertiana. A rare passion fruit n...   \n",
       "2  The Canadian Armed Forces. 1  The first large-...   \n",
       "3  Cherry. Cherry trees are found throughout the ...   \n",
       "4  Not only is breastfeeding better for the baby,...   \n",
       "\n",
       "                                            negative  \n",
       "0  It is generally safe for pregnant women to eat...  \n",
       "1  The kola nut is the fruit of the kola tree, a ...  \n",
       "2  The Canadian Physician Health Institute (CPHI)...  \n",
       "3  The kola nut is the fruit of the kola tree, a ...  \n",
       "4  However, you still need some niacin each day; ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from download import download_with_progress, extract_tar_with_progress\n",
    "from load_corpus import read_triples_train_small\n",
    "\n",
    "files = [\n",
    "    {\n",
    "        \"url\": \"https://msmarco.z22.web.core.windows.net/msmarcoranking/triples.train.small.tar.gz\",\n",
    "        \"name\": \"triples.train.small.tar.gz\"\n",
    "    },\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    tsv_name = file[\"name\"].replace(\".tar.gz\", \".tsv\")\n",
    "    if not os.path.exists(tsv_name):\n",
    "        # download with progress\n",
    "        download_with_progress(file[\"url\"], file[\"name\"])\n",
    "        # extract with progress\n",
    "        extract_tar_with_progress(file[\"name\"], \".\")\n",
    "        # (optional) delete the archive to save space\n",
    "        # os.remove(file[\"name\"])\n",
    "\n",
    "print(\"Files downloaded and extracted.\")\n",
    "# Load the TSV into a DataFrame (note: use the extracted .tsv file)\n",
    "train_df = read_triples_train_small(limit=10000)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4a9e13-2882-42a0-9b7d-e1dbc58e9fdd",
   "metadata": {},
   "source": [
    "Training the DPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51fe0703-6296-44e0-be79-84a2e25e29cd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-09-05T16:38:40.986794Z"
    },
    "jupyter": {
     "is_executing": true
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zuber_purahoo2/datascience-venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "/tmp/ipykernel_3533/2995194053.py:74: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
      "/tmp/ipykernel_3533/2995194053.py:89: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10  Loss: 0.0258\n",
      "Epoch 3/10  Loss: 0.0137\n",
      "Epoch 4/10  Loss: 0.0073\n",
      "Epoch 5/10  Loss: 0.0043\n",
      "Epoch 6/10  Loss: 0.0024\n",
      "Epoch 7/10  Loss: 0.0015\n",
      "Epoch 8/10  Loss: 0.0010\n",
      "Epoch 9/10  Loss: 0.0008\n",
      "Epoch 10/10  Loss: 0.0006\n",
      "Training complete and models saved!\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 1️⃣ Imports --------------------\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    DPRQuestionEncoder, DPRQuestionEncoderTokenizer,\n",
    "    DPRContextEncoder, DPRContextEncoderTokenizer\n",
    ")\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# -------------------- 2️⃣ Config --------------------\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 16      # you can increase if GPU allows\n",
    "EPOCHS = 10           # for testing\n",
    "LEARNING_RATE = 4e-6\n",
    "\n",
    "# -------------------- 3️⃣ Dataset --------------------\n",
    "class DPRDataset(Dataset):\n",
    "    def __init__(self, dataFrame):\n",
    "        self.data = dataFrame\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        return {\n",
    "            \"query\": row[\"query\"],\n",
    "            \"positive_passage\": row[\"positive\"],\n",
    "            \"negative_passage\": row[\"negative\"]\n",
    "        }\n",
    "\n",
    "dataset = DPRDataset(train_df)\n",
    "\n",
    "# -------------------- 4️⃣ Collate Function --------------------\n",
    "Q_MAX_LEN = 64      # queries are short\n",
    "CTX_MAX_LEN = 256   # MS MARCO passages fit well here (try 128–256)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    queries   = [b[\"query\"] for b in batch]\n",
    "    positives = [b[\"positive_passage\"] for b in batch]\n",
    "    negatives = [b[\"negative_passage\"] for b in batch]\n",
    "\n",
    "    # tokenize (keep dynamic padding, align to 8 for Tensor Cores)\n",
    "    q_enc = question_tokenizer(\n",
    "        queries, padding=True, truncation=True, max_length=Q_MAX_LEN,\n",
    "        pad_to_multiple_of=8, return_tensors=\"pt\"\n",
    "    )\n",
    "    # one tokenization for all contexts\n",
    "    ctx_enc = context_tokenizer(\n",
    "        positives + negatives, padding=True, truncation=True, max_length=CTX_MAX_LEN,\n",
    "        pad_to_multiple_of=8, return_tensors=\"pt\"\n",
    "    )\n",
    "    return q_enc, ctx_enc\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn,\n",
    "                          num_workers=os.cpu_count(), pin_memory=torch.cuda.is_available()\n",
    "                          )\n",
    "\n",
    "# -------------------- 5️⃣ Load DPR Models --------------------\n",
    "# Question encoder\n",
    "question_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\").to(DEVICE)\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "\n",
    "# Context encoder\n",
    "context_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\").to(DEVICE)\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "\n",
    "# -------------------- 6️⃣ Optimizer --------------------\n",
    "optimizer = AdamW(list(question_encoder.parameters()) + list(context_encoder.parameters()), lr=LEARNING_RATE)\n",
    "\n",
    "# -------------------- 7️⃣ Training Loop --------------------\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    question_encoder.train(); context_encoder.train()\n",
    "    total = 0.0\n",
    "\n",
    "    for q_enc, ctx_enc in train_loader:\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # to GPU\n",
    "        q_enc   = {k: v.to(DEVICE, non_blocking=True) for k, v in q_enc.items()}\n",
    "        ctx_enc = {k: v.to(DEVICE, non_blocking=True) for k, v in ctx_enc.items()}\n",
    "\n",
    "        B = q_enc[\"input_ids\"].size(0)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "            q_out   = question_encoder(**q_enc).pooler_output                  # [B, H]\n",
    "            ctx_out = context_encoder(**ctx_enc).pooler_output                 # [2B, H]\n",
    "            p_out, n_out = ctx_out.split(B, dim=0)                             # each [B, H]\n",
    "\n",
    "            # cosine margin loss\n",
    "            pos = torch.cosine_similarity(q_out, p_out, dim=1)\n",
    "            neg = torch.cosine_similarity(q_out, n_out, dim=1)\n",
    "            loss = (0.2 - pos + neg).clamp_min_(0).mean()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}  Loss: {total/len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "# -------------------- 8️⃣ Save Models --------------------\n",
    "question_encoder.save_pretrained(\"./dpr_question_encoder\")\n",
    "context_encoder.save_pretrained(\"./dpr_context_encoder\")\n",
    "question_tokenizer.save_pretrained(\"./dpr_question_encoder\")\n",
    "context_tokenizer.save_pretrained(\"./dpr_context_encoder\")\n",
    "\n",
    "print(\"Training complete and models saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2f15f9-0365-410d-add5-aff993f0cfef",
   "metadata": {},
   "source": [
    "Encode documents & queries into embeddings, retrieve top-k docs (using FAISS or\n",
    "similar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a9aa48f-4249-42e0-b8eb-e40f58e84b56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T07:54:27.169773Z",
     "start_time": "2025-08-31T07:54:26.327984Z"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision@5: 0.2\n",
      "MAP: 1.0\n",
      "nDCG@5: 1.0\n"
     ]
    }
   ],
   "source": [
    "# -------------------- 1️⃣ Imports --------------------\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer, DPRContextEncoder, DPRContextEncoderTokenizer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score, ndcg_score\n",
    "\n",
    "# -------------------- 2️⃣ Config --------------------\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "TOP_K = 5\n",
    "TEST_SAMPLE = 5  # number of test triples to sample\n",
    "DATA_PATH = \"sample.tsv\"  # update path\n",
    "\n",
    "# -------------------- 3️⃣ Load & Sample Test Data --------------------\n",
    "df = pd.read_csv(DATA_PATH, sep=\"\\t\", names=[\"query\", \"positive\", \"negative\"])\n",
    "df = df.sample(TEST_SAMPLE, random_state=42).reset_index(drop=True)\n",
    "\n",
    "queries = df[\"query\"].tolist()\n",
    "positive_passages = df[\"positive\"].tolist()\n",
    "\n",
    "# -------------------- 4️⃣ Load Trained DPR Models --------------------\n",
    "question_encoder = DPRQuestionEncoder.from_pretrained(\"./dpr_question_encoder\").to(DEVICE)\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"./dpr_question_encoder\")\n",
    "\n",
    "context_encoder = DPRContextEncoder.from_pretrained(\"./dpr_context_encoder\").to(DEVICE)\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"./dpr_context_encoder\")\n",
    "\n",
    "# -------------------- 5️⃣ Encode Passages --------------------\n",
    "context_encoder.eval()\n",
    "passage_embeddings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(positive_passages), 16):\n",
    "        batch = positive_passages[i:i+16]\n",
    "        enc = context_tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(DEVICE)\n",
    "        enc = context_tokenizer(\n",
    "                batch,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512,   \n",
    "                return_tensors=\"pt\"\n",
    "            ).to(DEVICE)\n",
    "\n",
    "        emb = context_encoder(**enc).pooler_output\n",
    "        passage_embeddings.append(emb.cpu())\n",
    "\n",
    "passage_embeddings = torch.cat(passage_embeddings, dim=0).numpy()\n",
    "faiss.normalize_L2(passage_embeddings)  # for cosine similarity\n",
    "\n",
    "# -------------------- 6️⃣ Encode Queries --------------------\n",
    "question_encoder.eval()\n",
    "query_embeddings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(queries), 16):\n",
    "        batch = queries[i:i+16]\n",
    "        # enc = question_tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(DEVICE)\n",
    "        enc = question_tokenizer(\n",
    "            batch,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,   \n",
    "            return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        emb = question_encoder(**enc).pooler_output\n",
    "        query_embeddings.append(emb.cpu())\n",
    "\n",
    "query_embeddings = torch.cat(query_embeddings, dim=0).numpy()\n",
    "faiss.normalize_L2(query_embeddings)\n",
    "\n",
    "# -------------------- 7️⃣ FAISS Retrieval --------------------\n",
    "d = passage_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(d)  # inner product = cosine similarity\n",
    "index.add(passage_embeddings)\n",
    "D, I = index.search(query_embeddings, TOP_K)  # top-K indices\n",
    "\n",
    "# -------------------- 8️⃣ Evaluation --------------------\n",
    "# Define relevance: only the matching positive passage is relevant\n",
    "qrels = {i: [i] for i in range(len(queries))}\n",
    "\n",
    "# Precision@K\n",
    "def precision_at_k(retrieved_idx, relevant_idx, k):\n",
    "    retrieved_k = retrieved_idx[:k]\n",
    "    return len(set(retrieved_k) & set(relevant_idx)) / k\n",
    "\n",
    "precisions = [precision_at_k(I[q], qrels[q], TOP_K) for q in range(len(queries))]\n",
    "print(\"Mean Precision@5:\", np.mean(precisions))\n",
    "\n",
    "# MAP\n",
    "def mean_average_precision(retrieved_indices, qrels):\n",
    "    all_ap = []\n",
    "    for qid, retrieved in enumerate(retrieved_indices):\n",
    "        y_true = [1 if i in qrels[qid] else 0 for i in retrieved]\n",
    "        y_score = list(range(len(retrieved), 0, -1))  # simple ranking scores\n",
    "        if sum(y_true) > 0:\n",
    "            ap = average_precision_score(y_true, y_score)\n",
    "            all_ap.append(ap)\n",
    "    return np.mean(all_ap)\n",
    "\n",
    "map_score = mean_average_precision(I, qrels)\n",
    "print(\"MAP:\", map_score)\n",
    "\n",
    "# nDCG@K\n",
    "y_true = np.zeros((len(queries), len(positive_passages)))\n",
    "for qid, rel in qrels.items():\n",
    "    for pid in rel:\n",
    "        y_true[qid, pid] = 1\n",
    "\n",
    "y_score = np.zeros_like(y_true)\n",
    "for qid, retrieved in enumerate(I):\n",
    "    for rank, pid in enumerate(retrieved):\n",
    "        y_score[qid, pid] = 1 / (rank + 1)\n",
    "\n",
    "ndcg = ndcg_score(y_true, y_score, k=TOP_K)\n",
    "print(\"nDCG@5:\", ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4590734-6f98-464d-8c01-1f788f184709",
   "metadata": {},
   "source": [
    "Comparing the truth value to the retrieved one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cef4c9e2-dae6-4490-b03e-66aeb6cd429b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T07:54:35.478586Z",
     "start_time": "2025-08-31T07:54:35.336406Z"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Ground Truth Positive</th>\n",
       "      <th>Top-k Retrieved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weather in austin tx in march...</td>\n",
       "      <td>Average Weather in March in Austin Texas, Unit...</td>\n",
       "      <td>1. Average Weather in March in Austin Texas, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the navy leave instruction...</td>\n",
       "      <td>July 2, Secretary of the Navy Ray Mabus announ...</td>\n",
       "      <td>1. July 2, Secretary of the Navy Ray Mabus ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is a retrovirus and name an example....</td>\n",
       "      <td>Retrovirus, any of a group of viruses that bel...</td>\n",
       "      <td>1. Retrovirus, any of a group of viruses that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is considered a normal dosage for xanax...</td>\n",
       "      <td>The usual starting Xanax dosage is 0.25 mg to ...</td>\n",
       "      <td>1. The usual starting Xanax dosage is 0.25 mg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>personal tax rates 2015 us...</td>\n",
       "      <td>The United States federal government taxes per...</td>\n",
       "      <td>1. The United States federal government taxes ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Query  \\\n",
       "0                 weather in austin tx in march...   \n",
       "1            what is the navy leave instruction...   \n",
       "2     what is a retrovirus and name an example....   \n",
       "3  what is considered a normal dosage for xanax...   \n",
       "4                    personal tax rates 2015 us...   \n",
       "\n",
       "                               Ground Truth Positive  \\\n",
       "0  Average Weather in March in Austin Texas, Unit...   \n",
       "1  July 2, Secretary of the Navy Ray Mabus announ...   \n",
       "2  Retrovirus, any of a group of viruses that bel...   \n",
       "3  The usual starting Xanax dosage is 0.25 mg to ...   \n",
       "4  The United States federal government taxes per...   \n",
       "\n",
       "                                     Top-k Retrieved  \n",
       "0  1. Average Weather in March in Austin Texas, U...  \n",
       "1  1. July 2, Secretary of the Navy Ray Mabus ann...  \n",
       "2  1. Retrovirus, any of a group of viruses that ...  \n",
       "3  1. The usual starting Xanax dosage is 0.25 mg ...  \n",
       "4  1. The United States federal government taxes ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "# Make sure corpus exists (the same list used to build FAISS index)\n",
    "corpus = df[\"positive\"].tolist() + df[\"negative\"].tolist()\n",
    "\n",
    "# -------------------- Show Queries, Positives & Retrievals --------------------\n",
    "def show_retrieval_results(queries, positive_passages, index, question_encoder, question_tokenizer, TOP_K=5):\n",
    "    results = []\n",
    "\n",
    "    for i, query in enumerate(queries[:5]):   # just show first 5 queries\n",
    "        # Encode query\n",
    "        q_enc = question_tokenizer([query], return_tensors=\"pt\", padding=True, truncation=True).to(DEVICE)\n",
    "        q_emb = question_encoder(**q_enc).pooler_output.cpu().detach().numpy()\n",
    "        \n",
    "        # Search FAISS\n",
    "        D, I = index.search(q_emb, TOP_K)\n",
    "\n",
    "        retrieved = []\n",
    "        for rank, idx in enumerate(I[0]):\n",
    "            passage = corpus[idx][:200] + \"...\"  # truncate for display\n",
    "            retrieved.append(f\"{rank+1}. {passage}\")\n",
    "\n",
    "        # Add to results table\n",
    "        results.append({\n",
    "            \"Query\": query[:200] + \"...\",\n",
    "            \"Ground Truth Positive\": positive_passages[i][:200] + \"...\",\n",
    "            \"Top-k Retrieved\": \"\\n\".join(retrieved)\n",
    "        })\n",
    "\n",
    "    # Pretty display\n",
    "    df_results = pd.DataFrame(results)\n",
    "    display(df_results)\n",
    "\n",
    "# Call function\n",
    "show_retrieval_results(queries, positive_passages, index, question_encoder, question_tokenizer, TOP_K=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f96cba0fe56be",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
