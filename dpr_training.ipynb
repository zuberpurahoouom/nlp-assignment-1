{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c57ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zuber_purahoo2/datascience-venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import (\n",
    "    DPRQuestionEncoder, DPRQuestionEncoderTokenizer,\n",
    "    DPRContextEncoder, DPRContextEncoderTokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e2bb81",
   "metadata": {},
   "source": [
    "PHASE 1 - DATASET LOADING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da03ea",
   "metadata": {},
   "source": [
    "A 30K sample in the format of (query,positive passage,negative passage) is retrieved from the original dataset 'triples.train.small.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e895bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>pos_pid</th>\n",
       "      <th>positive</th>\n",
       "      <th>neg_pid</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000094</td>\n",
       "      <td>where is whitemarsh island</td>\n",
       "      <td>5399011</td>\n",
       "      <td>Whitemarsh Island, Georgia. Whitemarsh Island ...</td>\n",
       "      <td>4239068</td>\n",
       "      <td>Pea Island is an island which is part of the O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000094</td>\n",
       "      <td>where is whitemarsh island</td>\n",
       "      <td>5399011</td>\n",
       "      <td>Whitemarsh Island, Georgia. Whitemarsh Island ...</td>\n",
       "      <td>271630</td>\n",
       "      <td>Underwater Volcano Forms New South Pacific Isl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000094</td>\n",
       "      <td>where is whitemarsh island</td>\n",
       "      <td>5399011</td>\n",
       "      <td>Whitemarsh Island, Georgia. Whitemarsh Island ...</td>\n",
       "      <td>5534953</td>\n",
       "      <td>Komodo is one of the 17,508 islands that make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000684</td>\n",
       "      <td>where is your perineum</td>\n",
       "      <td>6133670</td>\n",
       "      <td>That part of the floor of the PELVIS that lies...</td>\n",
       "      <td>54955</td>\n",
       "      <td>rule of nines (rÅ«l nÄ«nz) Method used in calc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000684</td>\n",
       "      <td>where is your perineum</td>\n",
       "      <td>6133670</td>\n",
       "      <td>That part of the floor of the PELVIS that lies...</td>\n",
       "      <td>5952792</td>\n",
       "      <td>This delicate triangle is important during chi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid                       query  pos_pid  \\\n",
       "0  1000094  where is whitemarsh island  5399011   \n",
       "1  1000094  where is whitemarsh island  5399011   \n",
       "2  1000094  where is whitemarsh island  5399011   \n",
       "3  1000684      where is your perineum  6133670   \n",
       "4  1000684      where is your perineum  6133670   \n",
       "\n",
       "                                            positive  neg_pid  \\\n",
       "0  Whitemarsh Island, Georgia. Whitemarsh Island ...  4239068   \n",
       "1  Whitemarsh Island, Georgia. Whitemarsh Island ...   271630   \n",
       "2  Whitemarsh Island, Georgia. Whitemarsh Island ...  5534953   \n",
       "3  That part of the floor of the PELVIS that lies...    54955   \n",
       "4  That part of the floor of the PELVIS that lies...  5952792   \n",
       "\n",
       "                                            negative  \n",
       "0  Pea Island is an island which is part of the O...  \n",
       "1  Underwater Volcano Forms New South Pacific Isl...  \n",
       "2  Komodo is one of the 17,508 islands that make ...  \n",
       "3  rule of nines (rÅ«l nÄ«nz) Method used in calc...  \n",
       "4  This delicate triangle is important during chi...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### DO NOT USE THIS DATASET ########\n",
    "####### USE: qidpidtriples.top3.clean.tsv ########\n",
    "file_path = r\"qidpidtriples.top3.clean.tsv\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    file_path,\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=[\"qid\", \"query\", \"pos_pid\", \"positive\", \"neg_pid\", \"negative\"],\n",
    "    encoding='utf-16',\n",
    ")\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db890195",
   "metadata": {},
   "source": [
    "PHASE 2 - TRAIN-TEST SPLIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53083d4a",
   "metadata": {},
   "source": [
    "Split into train set (80%) and test set (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ee7441a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'qid': 1000094, 'query': 'where is whitemarsh island', 'pos_pid': 5399011, 'positive': 'Whitemarsh Island, Georgia. Whitemarsh Island (pronounced WIT-marsh) is a census-designated place (CDP) in Chatham County, Georgia, United States. The population was 6,792 at the 2010 census. It is part of the Savannah Metropolitan Statistical Area. The communities of Whitemarsh Island are a relatively affluent suburb of Savannah.', 'neg_pid': 4239068, 'negative': 'Pea Island is an island which is part of the Outer Banks of North Carolina. Because of the shifting nature of the barrier island system of which Pea Island is a part, and the way in which inlets open and close over time, Pea Island has, at times, been contiguous with the neighboring islands of Bodie Island or Hatteras Island.', '__index_level_0__': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "from datasets import Dataset\n",
    "df = df.dropna(subset=['positive','negative'])\n",
    "train_dataset = Dataset.from_pandas(df)\n",
    "\n",
    "print(train_dataset[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975c72a",
   "metadata": {},
   "source": [
    "PHASE 3: TRAINING STAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f50444",
   "metadata": {},
   "source": [
    "1. The first step is to load the question and context encoders of the DPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "691913dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)\n",
    "# Question encoder\n",
    "question_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\").to(DEVICE)\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "\n",
    "# Context encoder\n",
    "context_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\").to(DEVICE)\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4a9e13-2882-42a0-9b7d-e1dbc58e9fdd",
   "metadata": {},
   "source": [
    "2. Creation of the dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "154e1d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42274\n",
      "{'query': 'where is whitemarsh island', 'positive_passage': 'Whitemarsh Island, Georgia. Whitemarsh Island (pronounced WIT-marsh) is a census-designated place (CDP) in Chatham County, Georgia, United States. The population was 6,792 at the 2010 census. It is part of the Savannah Metropolitan Statistical Area. The communities of Whitemarsh Island are a relatively affluent suburb of Savannah.', 'negative_passage': 'Pea Island is an island which is part of the Outer Banks of North Carolina. Because of the shifting nature of the barrier island system of which Pea Island is a part, and the way in which inlets open and close over time, Pea Island has, at times, been contiguous with the neighboring islands of Bodie Island or Hatteras Island.'}\n"
     ]
    }
   ],
   "source": [
    "class DPRDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.data = hf_dataset\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data[idx]  \n",
    "        return {\n",
    "            \"query\": row[\"query\"],\n",
    "            \"positive_passage\": row[\"positive\"],\n",
    "            \"negative_passage\": row[\"negative\"]\n",
    "        }\n",
    "\n",
    "train_dpr_dataset = DPRDataset(train_dataset)\n",
    "\n",
    "print(len(train_dpr_dataset))\n",
    "print(train_dpr_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4301fd",
   "metadata": {},
   "source": [
    "3. Definition of the collate_fn() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af386bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE  = 16\n",
    "Q_MAX_LEN   = 64\n",
    "CTX_MAX_LEN = 256\n",
    "\n",
    "# Collate function for batching and tokenization\n",
    "def collate_fn(batch):\n",
    "    queries   = [b[\"query\"] for b in batch]\n",
    "    positives = [b[\"positive_passage\"] for b in batch]\n",
    "    negatives = [b[\"negative_passage\"] for b in batch]\n",
    "\n",
    "    # Tokenize queries\n",
    "    q_enc = question_tokenizer(\n",
    "        queries, padding=True, truncation=True, max_length=Q_MAX_LEN,\n",
    "        pad_to_multiple_of=8, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Tokenize passages (positives + negatives)\n",
    "    ctx_enc = context_tokenizer(\n",
    "        positives + negatives, padding=True, truncation=True, max_length=CTX_MAX_LEN,\n",
    "        pad_to_multiple_of=8, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    return q_enc, ctx_enc\n",
    "\n",
    "train_dpr_dataset = DPRDataset(train_dataset)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dpr_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8967b9b5",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c08e7759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2964/837769827.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=torch.cuda.is_available())\n",
      "/tmp/ipykernel_2964/837769827.py:30: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=torch.cuda.is_available()):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m     scaler.step(optimizer)\n\u001b[32m     43\u001b[39m     scaler.update()\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m avg_loss = total_loss / \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[32m     48\u001b[39m epoch_losses.append(avg_loss)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 5e-6\n",
    "\n",
    "optimizer = torch.optim.AdamW(list(question_encoder.parameters()) + list(context_encoder.parameters()),\n",
    "                              lr=LEARNING_RATE)\n",
    "\n",
    "scaler = GradScaler(enabled=torch.cuda.is_available())\n",
    "epoch_losses = []\n",
    "\n",
    "question_encoder.train()\n",
    "context_encoder.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for q_enc, ctx_enc in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # -------Move batch to GPU\n",
    "        q_enc   = {k: v.to(DEVICE, non_blocking=True) for k,v in q_enc.items()}\n",
    "        ctx_enc = {k: v.to(DEVICE, non_blocking=True) for k,v in ctx_enc.items()}\n",
    "\n",
    "        B = q_enc[\"input_ids\"].size(0)\n",
    "\n",
    "        # -------Forward pass with mixed precision\n",
    "        with autocast(enabled=torch.cuda.is_available()):\n",
    "            q_out   = question_encoder(**q_enc).pooler_output  # [B, H]\n",
    "            ctx_out = context_encoder(**ctx_enc).pooler_output  # [2B, H]\n",
    "            p_out, n_out = ctx_out.split(B, dim=0)\n",
    "\n",
    "            # -------Cosine margin loss\n",
    "            pos = torch.cosine_similarity(q_out, p_out, dim=1)\n",
    "            neg = torch.cosine_similarity(q_out, n_out, dim=1)\n",
    "            loss = (0.2 - pos + neg).clamp_min_(0).mean()\n",
    "\n",
    "        # -------Backward + optimizer step\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    epoch_losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}  Loss: {avg_loss:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(range(1, len(epoch_losses)+1), epoch_losses, marker='o')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Training Loss vs Epochs\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575cb54",
   "metadata": {},
   "source": [
    "Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19bfb55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete and models saved!\n"
     ]
    }
   ],
   "source": [
    "question_encoder.save_pretrained(\"./dpr_question_encoder\")\n",
    "context_encoder.save_pretrained(\"./dpr_context_encoder\")\n",
    "question_tokenizer.save_pretrained(\"./dpr_question_encoder\")\n",
    "context_tokenizer.save_pretrained(\"./dpr_context_encoder\")\n",
    "\n",
    "print(\"Training complete and models saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a2063a",
   "metadata": {},
   "source": [
    "Collect all passages for FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02ca8377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 passage_embeddings_80k.npy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# -------Load collection\n",
    "collection = pd.read_csv(\"common_dataset_80k.tsv\", sep=\"\\t\", names=[\"pid\", \"text\"], dtype={\"pid\": str, \"text\": str})\n",
    "\n",
    "embedding_filename = f\"passage_embeddings_{int(collection.shape[0]/1000)}k.npy\"\n",
    "\n",
    "print(len(collection), embedding_filename)  # -------smaller than full 8.8M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "724a95c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing passages (multi-process)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing (num_proc=4): 100%|██████████| 80000/80000 [00:44<00:00, 1791.93 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding passages...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 1250/1250 [20:53<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage embeddings shape: (80000, 768)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "context_encoder.eval()\n",
    "context_encoder.to(DEVICE)\n",
    "\n",
    "# ----------------------------------------------\n",
    "# Multi-process pre-tokenization with HuggingFace Datasets\n",
    "# ----------------------------------------------\n",
    "# Create a HF Dataset containing only the passage text column\n",
    "raw_ds = Dataset.from_pandas(collection[[\"text\"]])\n",
    "\n",
    "# Tokenization function (returns dict of model inputs)\n",
    "def tok(batch):\n",
    "    return context_tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",   # fixed length => tensorize easily\n",
    "        max_length=256,\n",
    "    )\n",
    "\n",
    "# Map with multiprocessing (adjust num_proc to available CPU cores)\n",
    "# remove original text column to save memory\n",
    "print(\"Tokenizing passages (multi-process)...\")\n",
    "tok_ds = raw_ds.map(\n",
    "    tok,\n",
    "    batched=True,\n",
    "    batch_size=512,\n",
    "    num_proc=4,          # change if you have fewer cores\n",
    "    remove_columns=[\"text\"],\n",
    "    desc=\"Tokenizing\"\n",
    ")\n",
    "\n",
    "# Set PyTorch format for direct tensor access\n",
    "Tok_COLUMNS = [c for c in [\"input_ids\", \"attention_mask\", \"token_type_ids\"] if c in tok_ds.column_names]\n",
    "tok_ds.set_format(type=\"torch\", columns=Tok_COLUMNS)\n",
    "\n",
    "# DataLoader to stream batches to the encoder (no need for workers now; already tokenized)\n",
    "EMB_BATCH_SIZE = 64  # tune based on GPU memory\n",
    "passage_loader = DataLoader(tok_ds, batch_size=EMB_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "passage_embeddings = []\n",
    "print(\"Encoding passages...\")\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(passage_loader, desc=\"Encoding\"):\n",
    "        batch = {k: v.to(DEVICE, non_blocking=True) for k, v in batch.items()}\n",
    "        emb = context_encoder(**batch).pooler_output  # [B, H]\n",
    "        passage_embeddings.append(emb.cpu())\n",
    "\n",
    "# Concatenate all batches\n",
    "passage_embeddings = torch.cat(passage_embeddings, dim=0).numpy()\n",
    "print(\"Passage embeddings shape:\", passage_embeddings.shape)\n",
    "\n",
    "# Save\n",
    "np.save(embedding_filename, passage_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429767d1",
   "metadata": {},
   "source": [
    "Save embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8b452cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 768)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load later\n",
    "passage_embeddings = np.load(embedding_filename)\n",
    "print(passage_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7070b6",
   "metadata": {},
   "source": [
    "Build FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9579bed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in FAISS: 80000\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "dim = passage_embeddings.shape[1]  # typically 768 for DPR\n",
    "faiss.normalize_L2(passage_embeddings)  # normalize for cosine similarity\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "index.add(passage_embeddings)\n",
    "\n",
    "print(\"Number of vectors in FAISS:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd9738",
   "metadata": {},
   "source": [
    "METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b430b8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmath\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfaiss\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/datascience-venv/lib/python3.13/site-packages/torch/__init__.py:2150\u001b[39m\n\u001b[32m   2143\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_compile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _disable_dynamo  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2145\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2146\u001b[39m \u001b[38;5;66;03m# Import interface functions defined in Python\u001b[39;00m\n\u001b[32m   2147\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2148\u001b[39m \n\u001b[32m   2149\u001b[39m \u001b[38;5;66;03m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2150\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF \u001b[38;5;28;01mas\u001b[39;00m _VF, functional \u001b[38;5;28;01mas\u001b[39;00m functional  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2151\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[32m   2153\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2154\u001b[39m \u001b[38;5;66;03m# Remove unnecessary members\u001b[39;00m\n\u001b[32m   2155\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/datascience-venv/lib/python3.13/site-packages/torch/functional.py:8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Optional, TYPE_CHECKING, Union\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _VF, Tensor\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _add_docstr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/datascience-venv/lib/python3.13/site-packages/torch/nn/__init__.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# mypy: allow-untyped-defs\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      3\u001b[39m     Buffer \u001b[38;5;28;01mas\u001b[39;00m Buffer,\n\u001b[32m      4\u001b[39m     Parameter \u001b[38;5;28;01mas\u001b[39;00m Parameter,\n\u001b[32m      5\u001b[39m     UninitializedBuffer \u001b[38;5;28;01mas\u001b[39;00m UninitializedBuffer,\n\u001b[32m      6\u001b[39m     UninitializedParameter \u001b[38;5;28;01mas\u001b[39;00m UninitializedParameter,\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# usort: skip # noqa: F403\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     10\u001b[39m     attention \u001b[38;5;28;01mas\u001b[39;00m attention,\n\u001b[32m     11\u001b[39m     functional \u001b[38;5;28;01mas\u001b[39;00m functional,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     utils \u001b[38;5;28;01mas\u001b[39;00m utils,\n\u001b[32m     17\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparallel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataParallel \u001b[38;5;28;01mas\u001b[39;00m DataParallel\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/datascience-venv/lib/python3.13/site-packages/torch/nn/modules/__init__.py:2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodule\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Module  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bilinear, Identity, LazyLinear, Linear  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mactivation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     CELU,\n\u001b[32m      5\u001b[39m     ELU,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     Threshold,\n\u001b[32m     33\u001b[39m )\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01madaptive\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdaptiveLogSoftmaxWithLoss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/datascience-venv/lib/python3.13/site-packages/torch/nn/modules/linear.py:7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F, init\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparameter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Parameter, UninitializedParameter\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlazy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LazyModuleMixin\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/datascience-venv/lib/python3.13/site-packages/torch/nn/functional.py:18\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _add_docstr, _infer_size\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_jit_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     12\u001b[39m     _overload,\n\u001b[32m     13\u001b[39m     boolean_dispatch,\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     BroadcastingList3,\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_torch_docs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m reproducibility_notes, sparse_support_notes, tf32_notes\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _reduction \u001b[38;5;28;01mas\u001b[39;00m _Reduction, grad  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodules\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _list_with_default, _pair, _single, _triple\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1022\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1118\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1218\u001b[39m, in \u001b[36mget_data\u001b[39m\u001b[34m(self, path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from transformers import DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "import pandas as pd\n",
    "from eval_metrics import average_precision_at_k, ndcg_at_k, recall_at_k\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Load DPR + FAISS + collection\n",
    "# ----------------------------\n",
    "question_encoder = DPRQuestionEncoder.from_pretrained(\"./dpr_question_encoder\").to(DEVICE)\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"./dpr_question_encoder\")\n",
    "\n",
    "# NOTE: passage_embeddings rows must align with collection rows (same order)\n",
    "passage_embeddings = np.load(\"passage_embeddings.npy\").astype(\"float32\")\n",
    "index = faiss.IndexFlatIP(passage_embeddings.shape[1])\n",
    "index.add(passage_embeddings)\n",
    "\n",
    "# 'collection' must have ['pid','text'] aligned to embeddings\n",
    "# e.g., collection = pd.read_csv(...); ensure pid is str\n",
    "collection[\"pid\"] = collection[\"pid\"].astype(str)\n",
    "pids_list = collection[\"pid\"].tolist()\n",
    "pid_set = set(pids_list)\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluation\n",
    "# ----------------------------\n",
    "def evaluate(queries_df: pd.DataFrame,\n",
    "             qrels_df: pd.DataFrame,\n",
    "             top_k=10,\n",
    "             recall_k=100):\n",
    "    \"\"\"\n",
    "    queries_df: DataFrame with columns ['qid','query'] (types as str)\n",
    "    qrels_df  : DataFrame with columns ['qid','pid','rel'] (pid, qid as str; rel int)\n",
    "    \"\"\"\n",
    "\n",
    "    # Build relevance maps per query\n",
    "    # rel_dict_by_qid: qid -> {pid: rel}  (supports graded relevance)\n",
    "    # rel_set_by_qid : qid -> {pid, ...}  (binary set for AP/Recall)\n",
    "    rel_dict_by_qid = {}\n",
    "    rel_set_by_qid = {}\n",
    "    for qid, group in qrels_df.groupby(\"qid\"):\n",
    "        d = {pid: int(rel) for pid, rel in zip(group[\"pid\"], group[\"rel\"])}\n",
    "        rel_dict_by_qid[qid] = d\n",
    "        rel_set_by_qid[qid]  = {pid for pid, r in d.items() if r > 0}\n",
    "\n",
    "    # Map qid -> query text\n",
    "    qid2query = dict(zip(queries_df[\"qid\"], queries_df[\"query\"]))\n",
    "    qids = list(qid2query.keys())\n",
    "    queries_list = [qid2query[q] for q in qids]\n",
    "\n",
    "    ap_scores, ndcg_scores, recall_scores = [], [], []\n",
    "\n",
    "    # We’ll retrieve max(top_k, recall_k)\n",
    "    search_k = max(top_k, recall_k)\n",
    "\n",
    "    for qid, q in tqdm(zip(qids, queries_list), total=len(queries_list), desc=\"Evaluating\"):\n",
    "        batch_qids = [qid]\n",
    "        batch_queries = [q]\n",
    "\n",
    "        enc = question_tokenizer(\n",
    "            batch_queries,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=64\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            q_emb = question_encoder(**enc).pooler_output          # [B, dim]\n",
    "            q_emb = torch.nn.functional.normalize(q_emb, p=2, dim=1)\n",
    "\n",
    "        D, I = index.search(q_emb.detach().cpu().numpy(), search_k)  # [B, search_k]\n",
    "\n",
    "        for b, qid in enumerate(batch_qids):\n",
    "            ranked_pids = [pids_list[idx] for idx in I[b]]\n",
    "            rel_dict = rel_dict_by_qid[qid]\n",
    "            rel_set  = rel_set_by_qid[qid]\n",
    "\n",
    "            # MAP@k (binary set)\n",
    "            ap_scores.append(average_precision_at_k(ranked_pids, rel_set, k=top_k))\n",
    "\n",
    "            # nDCG@k (graded rel via rel_dict; binary also works)\n",
    "            ndcg_scores.append(ndcg_at_k(ranked_pids, rel_dict, k=top_k))\n",
    "\n",
    "            # Recall@100 (binary)\n",
    "            recall_scores.append(recall_at_k(ranked_pids, rel_set, k=recall_k))\n",
    "\n",
    "    return {\n",
    "        f\"MAP@{top_k}\": float(np.mean(ap_scores)) if ap_scores else 0.0,\n",
    "        f\"nDCG@{top_k}\": float(np.mean(ndcg_scores)) if ndcg_scores else 0.0,\n",
    "        f\"Recall@{recall_k}\": float(np.mean(recall_scores)) if recall_scores else 0.0,\n",
    "        \"num_queries\": len(queries_list)\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# Run evaluation (same inputs as before, but PID-based)\n",
    "# ----------------------------\n",
    "queries = pd.read_csv(\"queries.dev.tsv\", sep=\"\\t\", names=[\"qid\", \"query\"],\n",
    "                      dtype={\"qid\": str, \"query\": str})\n",
    "qrels   = pd.read_csv(\"qrels.dev.tsv\", sep=\"\\t\", names=[\"qid\",\"_\",\"pid\",\"rel\"],\n",
    "                      dtype={\"qid\": str, \"pid\": str, \"rel\": int})\n",
    "\n",
    "# Keep only qrels whose pid exists in our (possibly sampled) collection\n",
    "qrels_for_eval = qrels[qrels[\"pid\"].isin(collection[\"pid\"])][[\"qid\",\"pid\",\"rel\"]].copy()\n",
    "\n",
    "# Use the subset of queries that appear in these qrels\n",
    "queries_eval = queries[queries[\"qid\"].isin(qrels_for_eval[\"qid\"])][[\"qid\",\"query\"]].drop_duplicates(\"qid\")\n",
    "\n",
    "sampled_queries = queries_eval.sample(1000, random_state=42)\n",
    "\n",
    "metrics = evaluate(sampled_queries, qrels_for_eval, top_k=10, recall_k=10)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af2627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
