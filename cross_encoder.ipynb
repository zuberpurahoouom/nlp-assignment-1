{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbfbe267-b989-4c7f-91fc-7ca3f81e60e5",
   "metadata": {},
   "source": "Data Loading"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:02:51.065727Z",
     "start_time": "2025-08-31T11:02:42.851939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "from load_corpus import read_collection\n",
    "from download import download_with_progress, extract_tar_with_progress\n",
    "\n",
    "\n",
    "files = [\n",
    "    {\n",
    "        \"url\": \"https://msmarco.z22.web.core.windows.net/msmarcoranking/qrels.train.tsv\",\n",
    "        \"name\": \"qrels.train.tsv\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    tsv_name = file[\"name\"].replace(\".tar.gz\", \".tsv\")\n",
    "    if not os.path.exists(tsv_name):\n",
    "        # download with progress\n",
    "        download_with_progress(file[\"url\"], file[\"name\"])\n",
    "\n",
    "        if file[\"name\"].endswith(\".tar.gz\"):\n",
    "            # extract with progress\n",
    "            extract_tar_with_progress(file[\"name\"], \".\")\n",
    "\n",
    "print(\"Files downloaded and extracted.\")\n",
    "\n",
    "# ---- Load Data ----\n",
    "queries = pd.read_csv(\"queries.train.tsv\", sep=\"\\t\", names=[\"qid\", \"query\"])\n",
    "collection = read_collection(\"collection.tsv\", limit=500000)\n",
    "qrels = pd.read_csv(\"qrels.train.tsv\", sep=\"\\t\", names=[\"qid\", \"pid\", \"relevance\"])"
   ],
   "id": "5f47a83c1fdfcff5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zuber_purahoo2/datascience-venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files downloaded and extracted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading collection: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500000/500000 [00:01<00:00, 459349.53it/s]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Formatting for the cross encoder",
   "id": "2382d3dcf93beb59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:02:51.543696Z",
     "start_time": "2025-08-31T11:02:51.353326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge to get (query, passage, label)\n",
    "df = qrels.merge(queries, on=\"qid\").merge(collection, on=\"pid\")\n",
    "df[\"label\"] = (df[\"relevance\"] > 0).astype(int)  # convert to binary relevance"
   ],
   "id": "ad48117ad47d57bf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model Training",
   "id": "5d02f9f28211750"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For cross encoder training, you need (query, passage, label) triplet",
   "id": "5dbbe074a0d19501"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:02:51.962052Z",
     "start_time": "2025-08-31T11:02:51.930947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load 1000 samples\n",
    "triples = pd.read_csv(\n",
    "    \"triples.train.small.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"query\", \"pos\", \"neg\"],\n",
    "    nrows=1000\n",
    ")\n",
    "\n",
    "# Convert to (query, passage, label)\n",
    "pos_df = triples[[\"query\", \"pos\"]].rename(columns={\"pos\": \"passage\"})\n",
    "pos_df[\"label\"] = 1\n",
    "\n",
    "neg_df = triples[[\"query\", \"neg\"]].rename(columns={\"neg\": \"passage\"})\n",
    "neg_df[\"label\"] = 0\n",
    "\n",
    "df = pd.concat([pos_df, neg_df]).reset_index(drop=True)\n",
    "\n",
    "print(\"Training pairs:\", df.shape)\n",
    "df.head()"
   ],
   "id": "fbd0874e85b6d5bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pairs: (2000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                            query  \\\n",
       "0        is a little caffeine ok during pregnancy   \n",
       "1               what fruit is native to australia   \n",
       "2              how large is the canadian military   \n",
       "3                            types of fruit trees   \n",
       "4  how many calories a day are lost breastfeeding   \n",
       "\n",
       "                                             passage  label  \n",
       "0  We donât know a lot about the effects of caf...      1  \n",
       "1  Passiflora herbertiana. A rare passion fruit n...      1  \n",
       "2  The Canadian Armed Forces. 1  The first large-...      1  \n",
       "3  Cherry. Cherry trees are found throughout the ...      1  \n",
       "4  Not only is breastfeeding better for the baby,...      1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is a little caffeine ok during pregnancy</td>\n",
       "      <td>We donât know a lot about the effects of caf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what fruit is native to australia</td>\n",
       "      <td>Passiflora herbertiana. A rare passion fruit n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how large is the canadian military</td>\n",
       "      <td>The Canadian Armed Forces. 1  The first large-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>types of fruit trees</td>\n",
       "      <td>Cherry. Cherry trees are found throughout the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how many calories a day are lost breastfeeding</td>\n",
       "      <td>Not only is breastfeeding better for the baby,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:02:52.820882Z",
     "start_time": "2025-08-31T11:02:52.815270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CrossEncoderDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length=256):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        enc = self.tokenizer(\n",
    "            row[\"query\"], row[\"passage\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in enc.items()}\n",
    "        item[\"labels\"] = row[\"label\"]\n",
    "        return item"
   ],
   "id": "18955daf1b513f46",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:02:54.105410Z",
     "start_time": "2025-08-31T11:02:53.838884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "train_dataset = CrossEncoderDataset(df, tokenizer)\n",
    "print(\"Dataset length:\", len(train_dataset))  # should print 2000"
   ],
   "id": "ced63e2139f4b4c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 2000\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:02:54.970522Z",
     "start_time": "2025-08-31T11:02:54.966249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = CrossEncoderDataset(df, tokenizer)\n",
    "print(\"Dataset length:\", len(train_dataset))  # should print 2000"
   ],
   "id": "8e0620b51e4d9c84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 2000\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:02:57.198731Z",
     "start_time": "2025-08-31T11:02:57.175593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load 100 triples for testing (not overlapping with training if you like)\n",
    "test_triples = pd.read_csv(\n",
    "    \"triples.train.small.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"query\", \"pos\", \"neg\"],\n",
    "    skiprows=1000,  # skip the first 1000 used for training\n",
    "    nrows=100\n",
    ")\n",
    "\n",
    "# Convert to (query, passage, label)\n",
    "pos_test = test_triples[[\"query\", \"pos\"]].rename(columns={\"pos\": \"passage\"})\n",
    "pos_test[\"label\"] = 1\n",
    "\n",
    "neg_test = test_triples[[\"query\", \"neg\"]].rename(columns={\"neg\": \"passage\"})\n",
    "neg_test[\"label\"] = 0\n",
    "\n",
    "test_df = pd.concat([pos_test, neg_test]).reset_index(drop=True)\n",
    "\n",
    "print(\"Test pairs:\", test_df.shape)\n",
    "test_df.head()"
   ],
   "id": "c39bf1222ff9b7e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test pairs: (200, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                    query  \\\n",
       "0  does long term heat harm bottled water   \n",
       "1                    closehandle function   \n",
       "2               how to get fitbit cheaper   \n",
       "3                            bastrop jail   \n",
       "4   wiley x customer service phone number   \n",
       "\n",
       "                                             passage  label  \n",
       "0  IBWA advises consumers to store bottled water ...      1  \n",
       "1  CloseHandle. The CloseHandle function closes a...      1  \n",
       "2  Amazon release this product on May 1, 2013. Th...      1  \n",
       "3  Here is jail inmate information for the Bastro...      1  \n",
       "4  Wiley X Customer Service Phone Numbers The Cus...      1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>passage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>does long term heat harm bottled water</td>\n",
       "      <td>IBWA advises consumers to store bottled water ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>closehandle function</td>\n",
       "      <td>CloseHandle. The CloseHandle function closes a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how to get fitbit cheaper</td>\n",
       "      <td>Amazon release this product on May 1, 2013. Th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bastrop jail</td>\n",
       "      <td>Here is jail inmate information for the Bastro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wiley x customer service phone number</td>\n",
       "      <td>Wiley X Customer Service Phone Numbers The Cus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:07:02.780456Z",
     "start_time": "2025-08-31T11:03:00.645090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./cross-encoder-msmarco\",\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=500,\n",
    "    eval_steps=5000,\n",
    "    save_steps=5000,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=os.cpu_count(),\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    torch_compile=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_df,  # you can create a dev set with qrels.dev.tsv\n",
    ")\n",
    "\n",
    "# ---- Train ----\n",
    "trainer.train()"
   ],
   "id": "7185c1b4fb275a9c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The speedups for torchdynamo mostly come with GPU Ampere or higher and which is not detected here.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1250/1250 03:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1250, training_loss=0.07367770610451699, metrics={'train_runtime': 238.3742, 'train_samples_per_second': 83.902, 'train_steps_per_second': 5.244, 'total_flos': 2631110553600000.0, 'train_loss': 0.07367770610451699, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save the model",
   "id": "94f9dd6e1c3ff4af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:07:22.426208Z",
     "start_time": "2025-08-31T11:07:21.220734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the model\n",
    "trainer.model.save_pretrained(\"./cross-encoder-msmarco\")\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(\"./cross-encoder-msmarco\")"
   ],
   "id": "9bb748c03900197a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./cross-encoder-msmarco/tokenizer_config.json',\n",
       " './cross-encoder-msmarco/special_tokens_map.json',\n",
       " './cross-encoder-msmarco/vocab.txt',\n",
       " './cross-encoder-msmarco/added_tokens.json',\n",
       " './cross-encoder-msmarco/tokenizer.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sampling a test set (different from the training set) to pass in the trainer function",
   "id": "7f8b1c52ca844c75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Saving the test data for cross encoder",
   "id": "2d8cf0550b7d1c3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:07:26.577441Z",
     "start_time": "2025-08-31T11:07:26.565276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save test dataset to a TSV file\n",
    "test_df.to_csv(\"test_cross_encoder.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Saved test dataset to test_cross_encoder.tsv\")"
   ],
   "id": "d9d34fcda3817cc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test dataset to test_cross_encoder.tsv\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load the trained model for evaluation",
   "id": "689137cb02805796"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:07:28.399597Z",
     "start_time": "2025-08-31T11:07:28.246189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load saved model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./cross-encoder-msmarco\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./cross-encoder-msmarco\")\n",
    "model.eval()  # set to evaluation mode"
   ],
   "id": "8907ce982d0a541",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:07:30.562910Z",
     "start_time": "2025-08-31T11:07:30.553942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv(\"test_cross_encoder.tsv\", sep=\"\\t\")"
   ],
   "id": "c2cade547173a84f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Score passages for a query and rank them",
   "id": "9b44bc9d9eb9cef3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:07:32.901807Z",
     "start_time": "2025-08-31T11:07:32.187875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"does long term heat harm bottled water\"\n",
    "candidates = test_df[test_df[\"query\"] == query]\n",
    "passages = candidates[\"passage\"].tolist()\n",
    "labels = candidates[\"label\"].tolist()\n",
    "\n",
    "# Tokenize query-passage pairs\n",
    "inputs = tokenizer([query]*len(passages), passages, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Score\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    scores = outputs.logits[:, 1].tolist()  # relevance score for label=1\n",
    "\n",
    "# Rank passages by score descending\n",
    "ranked = sorted(zip(passages, labels, scores), key=lambda x: x[2], reverse=True)\n",
    "print(\"Ranking:\")\n",
    "for passage, label, score in ranked:\n",
    "    print(f\"{score:.4f} | label={label} | {passage[:100]}...\")"
   ],
   "id": "77973e91b3052cf9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking:\n",
      "4.8678 | label=1 | IBWA advises consumers to store bottled water at room temperature or cooler, out of direct sunlight ...\n",
      "-3.8087 | label=0 | According to the International Bottled Water Association, âBottled water can be used indefinitely ...\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Compute ranking metrics",
   "id": "b5eecf5b96e24c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T11:07:42.240414Z",
     "start_time": "2025-08-31T11:07:42.231016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "y_true = [label for _, label, _ in ranked]\n",
    "y_score = [score for _, _, score in ranked]\n",
    "\n",
    "# Mean Average Precision (MAP)\n",
    "map_score = average_precision_score(y_true, y_score)\n",
    "print(\"MAP:\", map_score)\n",
    "\n",
    "# Precision@k\n",
    "k = 3\n",
    "precision_at_k = sum(y_true[:k])/k\n",
    "print(f\"Precision@{k}:\", precision_at_k)\n",
    "\n",
    "# nDCG@k\n",
    "def dcg(rels):\n",
    "    return sum((2**r - 1)/np.log2(i+2) for i,r in enumerate(rels))\n",
    "\n",
    "ideal = sorted(y_true, reverse=True)[:k]\n",
    "ndcg_score = dcg(y_true[:k])/dcg(ideal) if dcg(ideal) > 0 else 0\n",
    "print(f\"nDCG@{k}:\", ndcg_score)"
   ],
   "id": "cdb9e63c0bc11f6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 1.0\n",
      "Precision@3: 0.3333333333333333\n",
      "nDCG@3: 1.0\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "27a35b470ba2f06c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
